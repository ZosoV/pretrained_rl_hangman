# General config
run_name: "small_bert"
project_name: "pretrained_small_bert"
group_name: null
mode: "online" # "online" or "disabled" ("offline" too but not used)

# Bert config
hidden_size: 128 # 300 for using Glove embeddings
num_hidden_layers: 4  # Change as needed
num_attention_heads: 4
max_position_embeddings: 32  # Max word length
intermediate_size: 512
max_word_length: 32

# Training config
train_epochs: 200
learning_rate: 0.00005 # by scheduler goes to 0.0001 after warmup
enable_schedule: False
min_lr: null
batch_size: 128
warmup_steps: 15000

# Logging config
log_freq: 10
save_model: True
save_model_freq: 20
enable_evaluation: True

# Load prev model
load_model: False
load_model_path: "./models/model_2025_01_19-20_45_36/bert_model_0.pth"
